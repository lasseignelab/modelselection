---
title: "DataDownload_Fun"
author: "Avery Williams"
date: '2022-08-10'
output: html_document
---

> utilizing a function to pull RSEs from Recount3, make adjustments/filters to remove bad data, and save the RSEs as well as raw counts and TPM objects.

# required packages
```{r load packages}
library(recount)
library(recount3)
library(readr)
source("functions/rec3_rse_download.R") # change to where you have this function script saved
library(foreach)
library(doParallel)
library(bigmemory)
library(tidyverse)
```

# utilize function in rec3_rse_download.R
## NOTE: prerequisite is cellosaurus problematic cell line list that is available in this directory's /data folder, adjust cellosaurusfilepath and savefilepath accordingly 
```{r function run, message=FALSE, warning=FALSE}
#for(i in c("tcga", "gtex", "ccle", "hpa_c", "hpa_t", "pdx", "bone_t", "bone_n", "bone_c")){
# rec3_rse_download(project = i, cellosaurusfilepath = "data/problematic_celllines.csv", savefilepath = "data/recount3/") # will place full rse (with calc TPM), rawcounts, and tpm objects in destination folder
#}
```

## All non-TCGA/GTEx Studies
getSRAproj function accepts available projects ("ccle", "hpa_c", "hpa_t", "pdx", "bone_t", "bone_n", "bone_c") and filepath to cellosaurus file (if repo was cloned, should be at data/problematic_celllines.csv) and pulls RSE's, fixes mislabels, calculates TPM, and saves whole RSE's as .rds files in 'rse' folder and csv's for TPM and raw counts matrices in 'tpm' and 'raw_counts' folders, respectively



running gtex with parallelized sub-function of rec3_rse_download(), called getgtex
```{r}

cl <- makeCluster(4)
registerDoParallel(cl, cores = 4)

startTime <- Sys.time()
t <- getgtexrse(savefilepath = "../data/recount3/")
endTime <- Sys.time()
print(endTime - startTime)
getRawCounts(project = "gtex", savefilepath = "../data/recount3/test/") %>% write.csv(file = "../data/recount3/test/raw_counts/gtex_rawcounts.csv")

savetpm(savefilepath = "../data/recount3/test/") %>% write.csv(file = "../data/recount3/test/tpm/gtex_tpm.csv")

getTPM(project = "gtex", savefilepath = "../data/recount3/test/") %>% write.csv(file = "../data/recount3/test/tpm/gtex_tpm.csv")

stopCluster(cl)
```

read back in tpm and raw counts
```{r}
#fls <- list.files("../data/recount3/test/tpm", pattern = "*gtex_tpm.csv", full.names = TRUE)
#rsefiles <- Sys.glob(paste0("../data/recount3/test/tpm/*gtex_tpm.csv")) 

#startTime <- Sys.time()
#result_list <- sapply(rsefiles, function(x) get(eval(read.csv(x))))

#fls <- list.files("../data/recount3/tpm", pattern = "*gtex_tpm.csv", full.names = TRUE) %>% 
#  lapply(read_csv) %>% #bind_cols
#  reduce(full_join, by = "...1") #Error: vector memory exhausted (limit reached?) when running all gtex
#endTime <- Sys.time()
#print(endTime - startTime)
                      
```

running tcga with parallelized sub-function of rec3_rse_download(), called getgtex
```{r}
cl <- makeCluster(4)
registerDoParallel(cl, cores = 4)

startTime <- Sys.time()
t <- getTCGArse(savefilepath = "../data/recount3/test/")
endTime <- Sys.time()
print(endTime - startTime)

#reading in, splitting, and saving ###need to make these work with other projects
startTime <- Sys.time()
#getRawCounts(project = "tcga", savefilepath = "../data/recount3/test/") %>% write.csv(file = "../data/recount3/raw_counts/tcga_rawcounts.csv")

getTPM(project = "tcga", savefilepath = "../data/recount3/test/") %>% write.csv(file = "../data/recount3/tpm/tcga_tpm.csv")
endTime <- Sys.time()
print(endTime - startTime)

stopCluster(cl)


```

running getSRAproj function for non-TCGA/GTEx projects
```{r}
startTime <- Sys.time()
t <- getSRAproj(project = "bone_c", savefilepath = "../data/recount3/test/")


endTime <- Sys.time()
print(endTime - startTime)

```


